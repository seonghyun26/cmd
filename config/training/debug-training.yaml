batch_size: 4096
shuffle: True
epoch: 8
scale: 100.0
loss:
  name: MSE
  reduction: mean
optimizer:
  name: Adam
  params: {
    lr: 1e-3
  }
# scheduler:
#   name: ExponentialLR
#   params: {
#     gamma: 0.99
#   }
# scheduler:
#   name: ReduceLROnPlateau
#   params: {
#     gamma: 0.8,
#     milestones: [30, 80, 150]
#   }
scheduler:
  name: CosineAnnealingLR
  params: {
    T_max: 10,
    eta_min: 1e-5
  }
# scheduler:
#   name: CosineAnnealingWarmRestarts
#   params: {
#     T_0: 10,
#     T_mult: 1,
#     eta_min: 1e-5
#   }
num_workers: 8
train: True
test: False